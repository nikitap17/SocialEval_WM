**Import libraries using a reproducible approach**

```{r}
pkgs <- c("tidyverse",
          "ggpubr",
          "lme4",
          "lmerTest",
          "rstatix",
          "BayesFactor",
          "car",
          "emmeans",
          "modelbased",
          "rempsyc",
          "effectsize",
          "flextable",
          "parameters",
          "patchwork")

lapply(pkgs, library, character.only=TRUE)

options(es.use_symbols = TRUE)

```

```{r}
C_pallette = c("#FED789", "#5A8297", "#3C304B")
c1_low = C_pallette[1]
c2_high = C_pallette[2]
c3 = C_pallette[3]
```

### Data Preparation

```{r}
main_df <- read_csv("Data/clean_data/main_df.csv", show_col_types = FALSE)
main_df$ID <- factor(main_df$ID)
main_df$Evaluation <- factor(main_df$Evaluation)
main_df$CL <- factor(main_df$CL, levels = c("low","high"))
main_df$block <- factor(main_df$block)
main_df$trial_block <- factor(main_df$trial_block)

agg_df <- read_csv("Data/clean_data/agg_df.csv", show_col_types = FALSE)
agg_df$ID <- factor(agg_df$ID)
agg_df$Evaluation <- factor(agg_df$Evaluation)
agg_df$CL <- factor(agg_df$CL, levels = c("low","high"))

experiment_data <- read_csv("Data/clean_data/experiment_data.csv", show_col_types = FALSE)
experiment_data$ID <- factor(experiment_data$ID)
experiment_data$Evaluation <- factor(experiment_data$Evaluation)
experiment_data$CL <- factor(experiment_data$CL, levels = c("low","high"))
experiment_data$block <- factor(experiment_data$block)
experiment_data$trial_block <- factor(experiment_data$trial_block)
```


# Confirmatory Analyses

## Analyses for Reaction Time (RT)

### Classic ANOVA (Type III Sum of Squares)

```{r}
## Option 1 (used to obtain a tidy table)
aov <- anova_test(data = agg_df, RT_Raw ~ CL*Evaluation + Error(ID/(CL+Evaluation)), type =3,
                  effect.size="pes")
aov_table <- get_anova_table(aov)
aov_table

## Option 2 (used to generate epsilon square)
type3 <- list(CL = contr.sum, Evaluation = contr.sum)
m_aov3 <- lmer(RT_Raw ~ CL*Evaluation + (CL+Evaluation|ID),
               data = agg_df, contrasts = type3)

aov3 <- anova(m_aov3)
aov3
#eta_squared(aov3,partial=T, alternative = "two.sided")
epsilon_aov3 <- epsilon_squared(aov3, partial=T, alternative = "two.sided")

##partial eta/omega/epsilon is appropriate, if all variables in a design are manipulated
##(Olejnik & Algina, 2003)##


# Main Effects, no interaction effects
aov_table <- aov_table[,1:5]
epsilon_aov3 <- epsilon_aov3 %>% dplyr::select(-"CI")

colnames(aov_table)[1] <- "Parameter"

aovRT <- as_tibble(inner_join(aov_table,epsilon_aov3, by= "Parameter"))
table <- nice_table(aovRT, 
                    title = c("Table X", "Two-Way Repeated-Measures ANOVA for Reaction Time (Type III Sum of Squares)"),
                    note = c(
                      "* p < .05, ** p < .01, *** p < .001. CL = Cognitive Load; CI = Confidence Interval."
                    ))

save_as_docx(table, path = "TablesFigures/Table 1 - ANOVA_RT.docx")

estimate_means(m_aov3, ~CL)
estimate_means(m_aov3, ~Evaluation)
```

### Classic ANOVA (Type II Sum of Suares)

```{r}
cat("Option 1 (used to obtain a tidy table)\n")
aov <- anova_test(data = agg_df, RT_Raw ~ CL*Evaluation + Error(ID/(CL+Evaluation)), type=2,
                  effect.size="pes")
aov_table <- get_anova_table(aov)
aov_table


cat("\nOption 2 (used to generate epsilon square)\n")
m_aov3 <- lmer(RT_Raw ~ CL*Evaluation + (CL+Evaluation|ID),
               data = agg_df)

aov3 <- anova(m_aov3, type=2)
aov3
effectsize::eta_squared(aov3,partial=T, alternative = "two.sided")
epsilon_aov3 <- epsilon_squared(aov3, partial=T, alternative = "two.sided")
```

### Linear Mixed Models

Selecting the model

```{r}
m1 <- lmer(scale(RT_Raw) ~ CL*Evaluation + (1|ID),
           data=main_df, REML = T)

m1a <- lmer(scale(RT_Raw) ~ CL*Evaluation + (1|ID) + (0 + CL|ID),
            data=main_df, REML = T)

m1b <- lmer(scale(RT_Raw) ~ CL*Evaluation + (1|ID) + (0 + Evaluation|ID),
            data=main_df, REML = T)

m1c <- lmer(scale(RT_Raw) ~ CL*Evaluation + (1|ID) + (0 + CL+Evaluation|ID),
            data=main_df, REML = T)

m1d <- lmer(scale(RT_Raw) ~ CL*Evaluation + (CL+Evaluation|ID),
           data=main_df, REML = T)

m1e <- lmer(scale(RT_Raw) ~ CL*Evaluation + (CL*Evaluation|ID),
           data=main_df, REML = T)

AIC(m1,m1a,m1b, m1c, m1d, m1e)[order(AIC(m1,m1a,m1b, m1c, m1d, m1e)[,"AIC"]),] # prefers m1e
BIC(m1,m1a,m1b, m1c, m1d, m1e)[order(BIC(m1,m1a,m1b, m1c, m1d, m1e)[,"BIC"]),] # prefers m1d
print("We will continue with the less complex model m1d")
```

Interaction vs. no interaction model

```{r}
m1a <- lmer(scale(RT_Raw) ~ CL+Evaluation + (CL+Evaluation|ID),
            data=main_df, REML = T)
m1b <- lmer(scale(RT_Raw) ~ CL*Evaluation + (CL+Evaluation|ID),
            data=main_df, REML = T)
AIC(m1a)-AIC(m1b)
BIC(m1a)-BIC(m1b)
RT_mod_simple <- m1a
print("No interaction model is preferred")
```

Compare different configurations of block And Timing block

```{r}
m1a <- lmer(scale(RT_Raw) ~ CL+Evaluation + (1|ID),
           data=main_df, REML = T)
m1b <- lmer(scale(RT_Raw) ~ CL+Evaluation + (CL+Evaluation|ID),
           data=main_df, REML = T)
m1c <- lmer(scale(RT_Raw) ~ CL*Evaluation + (CL+Evaluation|ID),
           data=main_df, REML = T)
m2 <- lmer(scale(RT_Raw) ~ block + CL+Evaluation + (CL+Evaluation|ID),
           data=main_df, REML = T)
m3 <- lmer(scale(RT_Raw) ~ trial_block + CL+Evaluation + (CL+Evaluation|ID),
           data=main_df, REML = T)
m4 <- lmer(scale(RT_Raw) ~ block + trial_block + CL+Evaluation + (CL+Evaluation|ID),
           data=main_df, REML = T)
m4a <- lmer(scale(RT_Raw) ~ block + trial_block + CL*Evaluation + (CL+Evaluation|ID),
           data=main_df, REML = T)

AIC(m1a,m1b,m1c,m2,m3,m4,m4a)[order(AIC(m1a,m1b,m1c,m2,m3,m4,m4a)[,"AIC"]),]
BIC(m1a,m1b,m1c,m2,m3,m4,m4a)[order(BIC(m1a,m1b,m1c,m2,m3,m4,m4a)[,"BIC"]),]

RT_mod <- m4 # m4 preferred
AIC(RT_mod)-AIC(RT_mod_simple)
BIC(RT_mod)-BIC(RT_mod_simple)
print("Extended model is preferred")
```

Get table for model comparisons

```{r}
model_equ <- c(
  "RT ~ CL + SEval + (1|ID)",
  "RT ~ CL + SEval + (CL + SEval|ID)",
  "RT ~ CL * SEval + (CL + SEval|ID)",
  "RT ~ condition_block + CL + SEval + (CL + SEval|ID)",
  "RT ~ trial_block + CL + SEval + (CL + SEval|ID)",
  "RT ~ condition_block + trial_block + CL + SEval + (CL + SEval|ID)",
  "RT ~ condition_block + trial_block + CL * SEval + (CL + SEval|ID)"
)

model_cmpr <- data.frame(
  "Model" = model_equ,
  "AIC" = round(AIC(m1a,m1b,m1c,m2,m3,m4,m4a)$AIC),
  "BIC" = round(BIC(m1a,m1b,m1c,m2,m3,m4,m4a)$BIC)
)
model_cmpr <- model_cmpr[order(model_cmpr$AIC),]

table <- nice_table(model_cmpr,
                    title = c("Table S1", "Linear Mixed Model Comparisons for Reaction Time"),
                    note = c(
                      "AIC = Akaike Information Criterion; BIC = Bayesian Information Criterion; CL = Cognitive Load; SEval = Social Evaluation."
                    ))

save_as_docx(table, path = "TablesFigures/Table S1 - Model Comparison RT.docx")

```


Get nice table for extended LMM

```{r}
t_ <- model_parameters(RT_mod)[1:6,] %>% dplyr::select(c("Coefficient", "SE", "CI_low", "CI_high", "p"))

# Extract unstandardized Beta
Beta_m <- lmer(RT_Raw ~ block + trial_block + CL+Evaluation + (CL+Evaluation|ID),
               data=main_df, REML = T)
t_Beta <- model_parameters(Beta_m)[1:6,] %>% dplyr::select("Parameter", "Coefficient")
colnames(t_Beta)[2] <- "unstB"
table <- cbind(t_Beta, t_)

table <- nice_table(table, 
                    title = c("Table A3", "No Interaction Linear Mixed Model"),
                    note = c(
                      "* p < .05, ** p < .01, *** p < .001. CL = Cognitive Load; CI = Confidence Interval."
                    ))
#table

save_as_docx(table, path = "TablesFigures/Table A3 - Extended LMM RT.docx")
```

Visualisation of EMM (calculated on interaction model)

```{r}
emm_mod <- lmer(scale(RT_Raw) ~ block + trial_block + CL*Evaluation + (CL+Evaluation|ID),
           data=main_df, REML = T)
emm <- estimate_means(emm_mod, ~CL*Evaluation)

plot_emm_rt <- ggplot(emm, aes(x = Evaluation, y = Mean, group = factor(CL), color=factor(CL),shape=CL, linetype = factor(CL))) +
  geom_point(position = position_dodge(width = 0.2), size = 2.5) +
  geom_line(position = position_dodge(width = 0.2), linewidth = 0.5) +
  geom_errorbar(aes(ymin=CI_low, ymax=CI_high), width=.2,
                position=position_dodge(0.2),linewidth=0.35,linetype=1)+
  labs(x = "Social Evaluation", y = "Reaction Time",
       color = "Cognitive Load", shape="Cognitive Load", linetype="Cognitive Load") +
  
  scale_x_discrete(labels = c("Control", "Evaluation"))+
  
  theme_classic() +

  scale_shape_manual(values = c(15, 19),
                     labels = c("Low", "High")) +  # Use square for H0 and circle for H1
  scale_color_manual(values = c(c1_low, c2_high),
                     labels = c("Low", "High")) +  # Orange color for H0 and dark green for H1
  scale_linetype_manual(values = c(1,2),
                       labels = c("Low", "High")) +
  
  #theme_classic() +
  theme(legend.text = element_text(size = 8),
        axis.title.x = element_text(vjust = -3),
        axis.title.y = element_text(vjust = 3),
        plot.margin = margin(b = 15, l=15))

#ggsave("TablesFigures/EMM RT Evaluation.jpeg",dpi=600,width = 4, height = 3)
```

stress and trial block

```{r}
mb <- lmer(scale(RT_Raw) ~ block*trial_block*Evaluation*CL + (CL+Evaluation|ID),
           data=main_df, REML = T)
summary(mb)
emm_eu <- estimate_means(mb, ~Evaluation*trial_block)

ggplot(emm_eu, aes(x = trial_block, y = Mean, group = Evaluation, shape= Evaluation, color = Evaluation,
                   linetype= Evaluation)) +
  geom_point(position = position_dodge(width = 0.2), size = 2.5) +
  geom_line(position = position_dodge(width = 0.2), size = 0.5) +
  geom_errorbar(aes(ymin=CI_low, ymax=CI_high), width=.2,
                position=position_dodge(0.2),linewidth=0.35,linetype=1)+
  labs(x = "Timing Blocks", y = "Reaction Time",
       color = "Social Evaluation", shape="Social Evaluation", linetype= "Social Evaluation") +
  
  scale_x_discrete(labels = c("1-10 Trials", "10-20 Trials", "20-30 Trials")) +
  
  scale_shape_manual(values = c(15, 19),
                     labels = c("Control", "Evaluation")) +  # Use square for H0 and circle for H1
  scale_color_manual(values = c(c1_low, c2_high),
                     labels = c("Control", "Evaluation")) +
  scale_linetype_manual(values = c(1,2),
                        labels = c("Control", "Evaluation")) +
  
  theme_classic() +
  theme(legend.text = element_text(size = 8),
        axis.title.x = element_text(vjust = -3),
        axis.title.y = element_text(vjust = 3),
        plot.margin = margin(b = 15, l=15))


# ggsave("TablesFigures/EMM RT Evaluation and trial block.jpeg",dpi=600,width = 4, height = 3)
```

block and trial_block

```{r}
emm_eu <- estimate_means(mb, ~block*trial_block)

ggplot(emm_eu, aes(x = trial_block, y = Mean, group = block, shape= block, color = block,
                   linetype=block)) +
  geom_point(position = position_dodge(width = 0.2), size = 2.5) +
  geom_line(position = position_dodge(width = 0.2), size = 0.5) +
  geom_errorbar(aes(ymin=CI_low, ymax=CI_high), width=.2,
                position=position_dodge(0.2),linewidth=0.35,linetype=1)+
  labs(x = "Timing Blocks", y = "Reaction Time",
       color = "block", shape="block", linetype = "block") +
  
  scale_shape_manual(values = c(15, 19),
                     labels = c("first", "second")) +  # Use square for H0 and circle for H1
  scale_color_manual(values = c(c1_low, c2_high),
                     labels = c("first", "second")) +
  scale_linetype_manual(values = c(1,2),
                        labels = c("first", "second")) +
  

  theme_classic() +
  theme(legend.text = element_text(size = 8),
        axis.title.x = element_text(vjust = -3),
        axis.title.y = element_text(vjust = 3),
        plot.margin = margin(b = 15, l=15)) +
  
  scale_x_discrete(labels = c("1-10 Trials", "10-20 Trials", "20-30 Trials"))

# ggsave("TablesFigures/EMM RT block and trial block.jpeg",dpi=300,width = 4, height = 3)
```

### Bayesian evidence accumulation Reaction Time

```{r}
bf_df <- subset(main_df, is.na(RT_Raw) == F)

### Interaction versus no Interaction

h0 = "Additive Model"
h1 = "Interaction Model"
s_size = seq(8, 43, by = 7)
bf_collect <- data.frame(sample_size = c(s_size,s_size),
                         Hypothesis = c(rep(h0,length(s_size)), rep(h1,length(s_size))))
permutations <- as.character(seq(1,100))
participants <- unique (bf_df$ID)

for (p in permutations){
  
  bfsH0 = c()
  bfsH1 = c()
  participants <- sample(participants)
  for (n in s_size){
    bf0 = lmBF(RT_Raw ~ block + trial_block + Evaluation+CL + ID, data = subset(bf_df, ID %in% participants[1:n]), 
               whichRandom="ID")
    bf1 = lmBF(RT_Raw ~ block + trial_block + Evaluation*CL + ID, data = subset(bf_df, ID %in% participants[1:n]), 
               whichRandom="ID")
    
    bfsH0 = c(bfsH0, log10(as.numeric(as.vector(bf0/bf1))))
    bfsH1 = c(bfsH1, log10(as.numeric(as.vector(bf1/bf0))))
  }
  cln <- colnames(bf_collect)
  bf_collect$p <- c(bfsH0,bfsH1)
  colnames(bf_collect) <- c(cln,p)
}

bf_collect1 <- bf_collect %>%
  mutate(logmean = rowMeans(bf_collect[,3:length(bf_collect)]),
         logsd = apply((bf_collect[,3:length(bf_collect)]), 1, sd))

write.csv(bf_collect1, "Data/clean_data/BFevidence_rt1.csv", row.names = F)
```

Plot 1

```{r}
bf_collect1 <- read_csv("Data/clean_data/BFevidence_rt1.csv", show_col_types = F)

bf_plot1 <- ggplot(bf_collect1, aes(x = sample_size, y = logmean, group = Hypothesis,
                       shape = Hypothesis, color = Hypothesis, fill = Hypothesis)) +
  geom_point(size = 2) +  
  geom_line(size = 0.5) +
  
  geom_ribbon(aes(ymin = logmean-logsd, ymax = logmean+logsd), alpha = 0.3, color=NA) +
  
  labs(x = "Sample Size", y = "log Bayes Factors") +
  
  scale_shape_manual(values = c(19,23)) +
  scale_color_manual(values = c(c1_low, c2_high),
                     labels = c("Additive Model", "Interaction Model")) +
  scale_fill_manual(values = c(c1_low, c2_high),
                    labels = c("Additive Model", "Interaction Model")) +
  
  theme_classic() +
  theme(legend.title = element_blank(),
        legend.position = "top",
        legend.text = element_text(size = 8),
        axis.title.x = element_text(vjust = -3),
        axis.title.y = element_text(vjust = 3),
        plot.margin = margin(b = 15, l=15)) +
  
  scale_x_continuous(breaks = bf_collect1$sample_size)

#ggsave("TablesFigures/BF_updates int vs no int.jpeg",dpi=300,width = 4, height = 3)
```



```{r}
### CL only versus No interaction

h0 = "Additive Model"
h1 = "CL Model"
s_size = seq(8, 43, by = 7)
bf_collect <- data.frame(sample_size = c(s_size,s_size),
                         Hypothesis = c(rep(h0,length(s_size)), rep(h1,length(s_size))))
permutations <- as.character(seq(1,100))
participants <- unique (bf_df$ID)

for (p in permutations){
  
  bfsH0 = c()
  bfsH1 = c()
  participants <- sample(participants)
  for (n in s_size){
    bf1 = lmBF(RT_Raw ~ block + trial_block + CL + ID, data = subset(bf_df, ID %in% participants[1:n]), 
               whichRandom="ID")
    bf0 = lmBF(RT_Raw ~ block + trial_block + Evaluation+CL + ID, data = subset(bf_df, ID %in% participants[1:n]), 
               whichRandom="ID")
    
    bfsH0 = c(bfsH0, log10(as.numeric(as.vector(bf0/bf1))))
    bfsH1 = c(bfsH1, log10(as.numeric(as.vector(bf1/bf0))))
  }
  cln <- colnames(bf_collect)
  bf_collect$p <- c(bfsH0,bfsH1)
  colnames(bf_collect) <- c(cln,p)
}

bf_collect2 <- bf_collect %>%
  mutate(logmean = rowMeans(bf_collect[,3:length(bf_collect)]),
         logsd = apply((bf_collect[,3:length(bf_collect)]), 1, sd))

write.csv(bf_collect2, "Data/clean_data/BFevidence_rt2.csv", row.names = F)

```

Plot 2

```{r}
bf_collect2 <- read_csv("Data/clean_data/BFevidence_rt2.csv", show_col_types = F)

bf_plot2 <- ggplot(bf_collect2, aes(x = sample_size, y = logmean, group = Hypothesis,
                       shape = Hypothesis, color = Hypothesis, fill = Hypothesis)) +
  geom_point(size = 2) +  
  geom_line(size = 0.5) +
  
  geom_ribbon(aes(ymin = logmean-logsd, ymax = logmean+logsd), alpha = 0.3, color=NA) +
  
  labs(x = "Sample Size", y = "log Bayes Factors") +
  
  scale_shape_manual(values = c(19, 15)) +
  scale_color_manual(values = c(c1_low, c3),
                     labels = c("Additive Model", "CL Model")) +
  scale_fill_manual(values = c(c1_low, c3),
                    labels = c("Additive Model", "CL Model")) +
  
  theme_classic() +
  theme(legend.title = element_blank(),
        legend.position = "none",  #remove for combined visualisation later
        legend.text = element_text(size = 8),
        axis.title.x = element_text(vjust = -3),
        axis.title.y = element_text(vjust = 3),
        plot.margin = margin(b = 15, l=15)) +
  
  scale_x_continuous(breaks = bf_collect2$sample_size)+
  scale_y_continuous(breaks=c(-4,-3,-2,-1,0,1,2,3,4))

#ggsave("TablesFigures/BF_updates CL vs CL+Evaluation.jpeg",dpi=300,width = 4, height = 3)
```

**merge Bayesian plots for RT**

```{r, fig.width=7, fig.height=3.5}
BF_rt_plot <- (bf_plot1 | bf_plot2) +
  plot_annotation(tag_levels = 'A', title = "Reaction Time") +
  plot_layout(guides = "collect") &
  theme(plot.tag = element_text(face = "bold"),
        legend.position='bottom',
        plot.title = element_text(hjust = 0.5))

# Display the combined plot
print(BF_rt_plot)
ggsave("TablesFigures/Figure 5AB - BF Analysis.jpeg", dpi = 600, width = 7, height = 3.5)
```


## Analyses for Errors

### Generalized Linear Mixed Model with binomial distribution (logistic regression)

Model Selection

```{r}
m1 <- glmer(Errors ~ CL*Evaluation + (1|ID),
           data=experiment_data, family = binomial)

m2 <- glmer(Errors ~ CL*Evaluation + (CL+Evaluation|ID),
            data=experiment_data, family = binomial)

paste("AIC: ",AIC(m1)-AIC(m2))
paste("BIC: ",BIC(m1)-BIC(m2))
```

```{r}
cat("Continue with less complex random structure\n\n")

summary(m1)
model_parameters(m1)[4,]
```

Compare interaction and no interaction models

```{r}
m1a <- glmer(Errors ~ CL+Evaluation + (1|ID),
             data=experiment_data, family = binomial)
AIC(m1a)-AIC(m1)
BIC(m1a)-BIC(m1)

errors_m_simple <- m1a

table <- model_parameters(errors_m_simple)[1:3,1:9] %>% dplyr::select(-c("CI","df_error"))
table$OR <- exp(table$Coefficient)
table$lower_CI <- exp(table$CI_low)
table$upper_CI <- exp(table$CI_high)
table <- table[,c(1,2,3,4,5,8,9,10,7)]

table <- nice_table(table, 
                    title = c("Table X", "Errors - No Interaction Generalized Linear Mixed Model - Simple"),
                    note = c(
                      "* p < .05, ** p < .01, *** p < .001. CL = Cognitive Load; CI = Confidence Interval."
                    ))
table

#save_as_docx(table, path = "TablesFigures/simple GLMM Errors.docx")
```

Extend the model with block and trial block

```{r}
m3 <- glmer(Errors ~ block + CL+Evaluation + (1|ID),
           data=experiment_data, family = binomial)

m4 <- glmer(Errors ~ trial_block + CL+Evaluation + (1|ID),
           data=experiment_data, family = binomial)

m5 <- glmer(Errors ~ block + trial_block + CL+Evaluation + (1|ID),
           data=experiment_data, family = binomial)


AIC(m3,m4,m5)[order(AIC(m3, m4, m5)$AIC),]
BIC(m3,m4,m5)[order(BIC(m3, m4, m5)$BIC),]
# model m5

errors_m <- m5
summary(errors_m)
car::Anova(errors_m, type=2)

## nice table
table <- model_parameters(errors_m)[1:6,1:9] %>% dplyr::select(-c("CI","df_error"))
table$OR <- exp(table$Coefficient)
table$ORciL <- exp(table$CI_low)
table$ORciH <- exp(table$CI_high)
table <- table[,c(1,2,3,4,5,8,9,10,7)]

table <- nice_table(table, 
                    title = c("Table X", "Errors - No-Interaction Generalized Linear Mixed Model - Full"),
                    note = c(
                      "* p < .05, ** p < .01, *** p < .001. CL = Cognitive Load; CI = Confidence Interval."
                    ))
#table

save_as_docx(table, path = "TablesFigures/Table 2 - Extended GLMM Errors.docx")
```

simple vs extended model

```{r}
AIC(errors_m)-AIC(errors_m_simple)
BIC(errors_m)-BIC(errors_m_simple)
```

### Visualisation

Evaluation and CL

```{r}
emm_eu <- estimate_means(errors_m, ~CL*Evaluation)

plot_emm_errors <- ggplot(emm_eu, aes(x = Evaluation, y = Probability, group = CL, shape= CL, color = CL,
                   linetype = CL)) +
  geom_point(position = position_dodge(width = 0.2), size = 2.5) +
  geom_line(position = position_dodge(width = 0.2), size = 0.5) +
  geom_errorbar(aes(ymin=CI_low, ymax=CI_high), width=.2,
                position=position_dodge(0.2),linewidth=0.35,linetype=1)+
  labs(x = "Social Evaluation", y = "Error Probability",
       color = "Cognitive Load", shape="Cognitive Load", linetype= "Cognitive Load") +
  
  scale_x_discrete(labels = c("Control", "Evaluation")) +
  
  scale_shape_manual(values = c(15, 19),
                     labels = c("Low", "High")) +
  scale_color_manual(values = c(c1_low, c2_high),
                     labels = c("Low", "High")) +
  scale_linetype_manual(values=c(1,2),
                        labels=c("Low","High")) +
  
  theme_classic() +
  theme(legend.text = element_text(size = 8),
        axis.title.x = element_text(vjust = -3),
        axis.title.y = element_text(vjust = 3),
        plot.margin = margin(b = 15, l=15))
  
# ggsave("TablesFigures/EMM Errors interaction GLMM.jpeg",dpi=300,width = 4, height = 3)
```

Evaluation and timing block

```{r}
m5aa <- glmer(Errors ~ block*trial_block*Evaluation*CL + (1|ID),
            data=experiment_data, family = binomial)

emm_eu <- estimate_means(m5aa, ~Evaluation*trial_block)

ggplot(emm_eu, aes(x = trial_block, y = Probability, group = Evaluation, shape= Evaluation, color = Evaluation,
                   linetype= Evaluation)) +
  geom_point(position = position_dodge(width = 0.2), size = 2.5) +
  geom_line(position = position_dodge(width = 0.2), size = 0.5) +
  geom_errorbar(aes(ymin=CI_low, ymax=CI_high), width=.2,
                position=position_dodge(0.2),linewidth=0.35,linetype=1)+
  labs(x = "Timing Blocks", y = "Error Probability",
       color = "Social Evaluation", shape="Social Evaluation", linetype= "Social Evaluation") +
  
  scale_shape_manual(values = c(15, 19),
                     labels = c("Control", "Evaluation")) +  # Use square for H0 and circle for H1
  scale_color_manual(values = c(c1_low, c2_high),
                     labels = c("Control", "Evaluation")) +
  scale_linetype_manual(values = c(1,2),
                        labels = c("Control", "Evaluation")) +
  
  theme_classic() +
  theme(legend.text = element_text(size = 8),
        axis.title.x = element_text(vjust = -3),
        axis.title.y = element_text(vjust = 3),
        plot.margin = margin(b = 15, l=15)) +
  
  scale_x_discrete(labels = c("1-10 Trials", "10-20 Trials", "20-30 Trials"))

# ggsave("TablesFigures/EMM Errors Evaluation and trial block.jpeg",dpi=300,width = 4, height = 3)
```

block and timing block

```{r}
emm_eu <- estimate_means(m5aa, ~ block*trial_block)

ggplot(emm_eu, aes(x = trial_block, y = Probability, group = block, shape= block, color = block,
                   linetype=block)) +
  geom_point(position = position_dodge(width = 0.2), size = 2.5) +
  geom_line(position = position_dodge(width = 0.2), size = 0.5) +
  geom_errorbar(aes(ymin=CI_low, ymax=CI_high), width=.2,
                position=position_dodge(0.2),linewidth=0.35,linetype=1)+
  labs(x = "Timing Blocks", y = "Error Probability",
       color = "block", shape="block", linetype="block") +
  
  scale_shape_manual(values = c(15, 19),
                     labels = c("first", "second")) +  # Use square for H0 and circle for H1
  scale_color_manual(values = c(c1_low, c2_high),
                     labels = c("first", "second")) +
  scale_linetype_manual(values = c(1,2),
                        labels = c("first", "second")) +
  
  theme_classic() +
  theme(legend.text = element_text(size = 8),
        axis.title.x = element_text(vjust = -3),
        axis.title.y = element_text(vjust = 3),
        plot.margin = margin(b = 15, l=15)) +
  
  scale_x_discrete(labels = c("1-10 Trials", "10-20 Trials", "20-30 Trials"))

# ggsave("TablesFigures/EMM Errors block and trial block.jpeg",dpi=300,width = 4, height = 3)
```

*merge emm figures for rt and errors*

```{r, fig.width=7, fig.height=4.5}
combined_plot <- (plot_emm_rt | plot_emm_errors) +
  plot_annotation(tag_levels = 'A') +
  plot_layout(guides = "collect") &
  theme(plot.tag = element_text(face = "bold"),
        legend.position='bottom')

# Display the combined plot
print(combined_plot)
ggsave("TablesFigures/Figure 4 - EMM WM Performance.jpeg",dpi=600, w= 7, h = 4.5)
```

### Bayesian evidence accumulation for Errors

```{r}
s_size = seq(8, 43, by = 7)

bf_collect_er1 <- data.frame(sample_size = c(s_size,s_size),
                         Hypothesis = c(rep("Additive Model",length(s_size)),
                                        rep("Interaction Model",length(s_size))))
bf_collect_er2 <- data.frame(sample_size = c(s_size,s_size),
                             Hypothesis = c(rep("Additive Model",length(s_size)),
                                            rep("CL Model",length(s_size))))

permutations <- as.character(seq(1,100))
participants <- unique (experiment_data$ID)

for (p in permutations){
  
  # comparison no int vs. int
  no.int1 <- c()
  int = c()
  # comparison no int vs. cl
  no.int2 <- c()
  cl <- c()
  
  participants <- sample(participants)
  
  for (n in s_size){
    
    # calculate BICs for each model and subset
    no.int_m <- BIC(glmer(Errors ~ block + trial_block + CL+Evaluation + (1|ID),
                      data=subset(experiment_data, ID %in% participants[1:n]), family = binomial))
    int_m <- BIC(glmer(Errors ~ block + trial_block + CL*Evaluation + (1|ID),
                      data=subset(experiment_data, ID %in% participants[1:n]), family = binomial))
    cl_m <- BIC(glmer(Errors ~ block + trial_block + CL + (1|ID),
                  data=subset(experiment_data, ID %in% participants[1:n]), family = binomial))

    # calculate approximate BFs for each comparison
    no.int1 <- c(no.int1, log10(exp((int_m - no.int_m)/2)))
    int <- c(int, log10(exp((no.int_m - int_m)/2)))
    
    no.int2 <- c(no.int2, log10(exp((cl_m-no.int_m)/2)))
    cl <- c(cl, log10(exp((no.int_m-cl_m)/2)))
  }
  
  # arrange the data frames
  cln <- colnames(bf_collect_er1)
  bf_collect_er1$p <- c(no.int1,int)
  colnames(bf_collect_er1) <- c(cln,p)
  
  cln <- colnames(bf_collect_er2)
  bf_collect_er2$p <- c(no.int2,cl)
  colnames(bf_collect_er2) <- c(cln,p)
}

write.csv(bf_collect_er1, "Data/clean_data/BFevidence_er1.csv", row.names =  F)
write.csv(bf_collect_er2, "Data/clean_data/BFevidence_er2.csv", row.names =  F)

```

Plotting

```{r}
bf_collect_er1 <- read_csv("Data/clean_data/BFevidence_er1.csv", show_col_types = F)
bf_collect_er2 <- read_csv("Data/clean_data/BFevidence_er2.csv", show_col_types = F)

### additive vs. interaction

bf_collect_er1 <- bf_collect_er1 %>%
  dplyr::mutate(logmean = rowMeans(bf_collect_er1[,3:length(bf_collect_er1)]),
         logsd = apply((bf_collect_er1[,3:length(bf_collect_er1)]), 1, sd))

bf_plot3 <- ggplot(bf_collect_er1, aes(x = sample_size, y = logmean, group = Hypothesis,
                        shape = Hypothesis, color = Hypothesis, fill = Hypothesis)) +
  geom_point(size = 2) +  
  geom_line(size = 0.5) +
  
  geom_ribbon(aes(ymin = logmean-logsd, ymax = logmean+logsd), alpha = 0.3, color=NA) +
  
  labs(x = "Sample Size", y = "log Bayes Factors") +
  scale_shape_manual(values = c(19, 23)) +  # Use square for H0 and circle for H1
  
  scale_color_manual(values = c(c1_low, c2_high)) +
  scale_fill_manual(values = c(c1_low, c2_high)) +
  
  theme_classic() +
  theme(legend.title = element_blank(),
        legend.position = "top",
        legend.text = element_text(size = 8),
        axis.title.x = element_text(vjust = -3),
        axis.title.y = element_text(vjust = 3),
        plot.margin = margin(b = 15, l=15)) +
  
  scale_x_continuous(breaks = bf_collect_er1$sample_size)

#ggsave("TablesFigures/BF_updates ER int vs no int.jpeg",dpi=300,width = 4, height = 3)


### no interaction vs. CL model

bf_collect_er2 <- bf_collect_er2 %>%
  mutate(logmean = rowMeans(bf_collect_er2[,3:length(bf_collect_er2)]),
         logsd = apply((bf_collect_er2[,3:length(bf_collect_er2)]), 1, sd))

bf_plot4 <- ggplot(bf_collect_er2, aes(x = sample_size, y = logmean, group = Hypothesis,
                           shape = Hypothesis, color = Hypothesis, fill = Hypothesis)) +
  geom_point(size = 2) +  
  geom_line(size = 0.5) +
  
  geom_ribbon(aes(ymin = logmean-logsd, ymax = logmean+logsd), alpha = 0.3, color=NA) +
  
  labs(x = "Sample Size", y = "log Bayes Factors") +
  scale_shape_manual(values = c(19, 15)) +
  
  scale_color_manual(values = c(c1_low, c3)) +
  scale_fill_manual(values = c(c1_low, c3)) +
  
  theme_classic() +
  theme(legend.title = element_blank(),
        legend.position = "top",
        legend.text = element_text(size = 8),
        axis.title.x = element_text(vjust = -3),
        axis.title.y = element_text(vjust = 3),
        plot.margin = margin(b = 15, l=15)) +
  
  scale_x_continuous(breaks = bf_collect_er2$sample_size)+
  scale_y_continuous(breaks = c(-2,-1,-0.5,0,0.5,1,2))

#ggsave("TablesFigures/BF_updates ER cl vs no int.jpeg",dpi=300,width = 4, height = 3)
```

**merge bf pltos**

```{r, fig.width=7, fig.height=3.5}
BF_er_plot <- (bf_plot3 | bf_plot4) +
  plot_annotation(tag_levels = list(c("C", "D")), title = "Errors") +
  plot_layout(guides = "collect") &
  theme(plot.tag = element_text(face = "bold"),
        legend.position='bottom',
        plot.title = element_text(hjust = 0.5))

# Display the combined plot
print(BF_er_plot)
ggsave("TablesFigures/Figure 5CD - BF Analysis.jpeg", dpi = 600, width = 7, height = 3.5)
```

## Compare Errors, commission errors, and omission errors

commission errors

```{r}
cER_m <- glmer(cER ~ block + trial_block + CL+Evaluation + (1|ID),
               data=experiment_data, family = binomial)
summary(cER_m)
emm <- estimate_means(cER_m, ~CL*Evaluation)

ggplot(emm, aes(x = Evaluation, y = Probability, group = CL, shape= CL, color = CL,
                   linetype = CL)) +
  geom_point(position = position_dodge(width = 0.2), size = 2.5) +
  geom_line(position = position_dodge(width = 0.2), size = 0.5) +
  geom_errorbar(aes(ymin=CI_low, ymax=CI_high), width=.2,
                position=position_dodge(0.2),linewidth=0.35,linetype=1)+
  labs(x = "Social Evaluation", y = "Error Probability",
       color = "Cognitive Load", shape="Cognitive Load", linetype= "Cognitive Load") +
  
  scale_x_discrete(labels = c("Control", "Evaluation")) +
  
  scale_shape_manual(values = c(15, 19),
                     labels = c("Low", "High")) +
  scale_color_manual(values = c(c1_low, c2_high),
                     labels = c("Low", "High")) +
  scale_linetype_manual(values=c(1,2),
                        labels=c("Low","High")) +
  
  theme_classic() +
  theme(legend.text = element_text(size = 8),
        axis.title.x = element_text(vjust = -3),
        axis.title.y = element_text(vjust = 3),
        plot.margin = margin(b = 15, l=15))
```

omission errors

```{r}
oER_m <- glmer(oER ~ block + trial_block + CL+Evaluation + (1|ID),
            data=experiment_data, family = binomial)
summary(oER_m)
emm <- estimate_means(oER_m, ~CL*Evaluation)

ggplot(emm, aes(x = Evaluation, y = Probability, group = CL, shape= CL, color = CL,
                   linetype = CL)) +
  geom_point(position = position_dodge(width = 0.2), size = 2.5) +
  geom_line(position = position_dodge(width = 0.2), size = 0.5) +
  geom_errorbar(aes(ymin=CI_low, ymax=CI_high), width=.2,
                position=position_dodge(0.2),linewidth=0.35,linetype=1)+
  labs(x = "Social Evaluation", y = "Error Probability",
       color = "Cognitive Load", shape="Cognitive Load", linetype= "Cognitive Load") +
  
  scale_x_discrete(labels = c("Control", "Evaluation")) +
  
  scale_shape_manual(values = c(15, 19),
                     labels = c("Low", "High")) +
  scale_color_manual(values = c(c1_low, c2_high),
                     labels = c("Low", "High")) +
  scale_linetype_manual(values=c(1,2),
                        labels=c("Low","High")) +
  
  theme_classic() +
  theme(legend.text = element_text(size = 8),
        axis.title.x = element_text(vjust = -3),
        axis.title.y = element_text(vjust = 3),
        plot.margin = margin(b = 15, l=15))
```

*Both commission and omission errors show the same direction of effects as errors overall*

## Perceived Evaluation (Eustress and Distress ratings)

### Relation to performance and manipulation

Reaction Time

```{r}
m1 <- lmer(scale(RT_Raw) ~ block + trial_block + CL + Evaluation + scale(Eustress) + (1|ID),
           data=main_df, REML = T)
m2 <- lmer(scale(RT_Raw) ~ block + trial_block + CL + Evaluation + scale(Distress) + (1|ID),
           data=main_df, REML = T)
m3 <- lmer(scale(RT_Raw) ~ block + trial_block + CL + Evaluation + scale(Eustress) + scale(Distress) + (1|ID),
           data=main_df, REML = T)
m4 <- lmer(scale(RT_Raw) ~ block + trial_block + CL + Evaluation + scale(Eustress)*scale(Distress) + (1|ID),
           data=main_df, REML = T)

AIC(m1,m2,m3,m4)[order(AIC(m1,m2,m3,m4)$AIC),] #m1
BIC(m1,m2,m3,m4)[order(BIC(m1,m2,m3,m4)$BIC),] #m1

perc.stress.m <- m1
summary(perc.stress.m)
model_parameters(perc.stress.m)
summary(lmer(RT_Raw ~ block + trial_block + CL + Evaluation + Eustress + (1|ID),
           data=main_df, REML = T))
```

Get table for model comparisons

```{r}
model_equ <- c(
  "RT ~ condition_block + trial_block + CL + SEval + Eustress + (1|ID)",
  "RT ~ condition_block + trial_block + CL + SEval + Distress + (1|ID)",
  "RT ~ condition_block + trial_block + CL + SEval + Eustress + Distress + (1|ID)",
  "RT ~ condition_block + trial_block + CL + SEval + Eustress * Distress + (1|ID)"
)

model_cmpr <- data.frame(
  "Model" = model_equ,
  "AIC" = round(AIC(m1,m2,m3,m4)$AIC),
  "BIC" = round(BIC(m1,m2,m3,m4)$BIC)
)
model_cmpr <- model_cmpr[order(model_cmpr$AIC),]

table <- nice_table(model_cmpr,
                    title = c("Table S2", "Motivational States - Linear Mixed Model Comparisons for Reaction Time"),
                    note = c(
                      "AIC = Akaike Information Criterion; BIC = Bayesian Information Criterion; RT = reaction time; CL = cognitive load; SEval = social evaluation."
                    ))

save_as_docx(table, path = "TablesFigures/Table S2 - ADES Model Comparison RT.docx")

```

Errors

```{r}
m1 <- glmer(Errors ~ block + trial_block + CL + scale(Eustress) + (1|ID),
           data=experiment_data, family = binomial)
m2 <- glmer(Errors ~ block + trial_block + CL + scale(Distress) + (1|ID),
           data=experiment_data, family = binomial)
m3 <- glmer(Errors ~ block + trial_block + CL + scale(Eustress) + scale(Distress) + (1|ID),
           data=experiment_data, family = binomial)
m4 <- glmer(Errors ~ block + trial_block + CL + scale(Eustress)*scale(Distress) + (1|ID),
           data=experiment_data, family = binomial)

AIC(m1,m2,m3,m4)[order(AIC(m1,m2,m3,m4)$AIC),] #m3
BIC(m1,m2,m3,m4)[order(BIC(m1,m2,m3,m4)$BIC),] #m3


perc.stress.m <- m3
summary(perc.stress.m)
model_parameters(perc.stress.m, exponentiate = T)
model_parameters(glmer(Errors ~ block + trial_block + CL + Eustress + Distress + (1|ID),
           data=experiment_data, family = binomial))
```

Get table for model comparisons

```{r}
model_equ <- c(
  "Errors ~ condition_block + trial_block + CL + SEval + Eustress + (1|ID)",
  "Errors ~ condition_block + trial_block + CL + SEval + Distress + (1|ID)",
  "Errors ~ condition_block + trial_block + CL + SEval + Eustress + Distress + (1|ID)",
  "Errors ~ condition_block + trial_block + CL + SEval + Eustress * Distress + (1|ID)"
)

model_cmpr <- data.frame(
  "Model" = model_equ,
  "AIC" = round(AIC(m1,m2,m3,m4)$AIC),
  "BIC" = round(BIC(m1,m2,m3,m4)$BIC)
)
model_cmpr <- model_cmpr[order(model_cmpr$AIC),]

table <- nice_table(model_cmpr,
                    title = c("Table S3", "Motivational States - Linear Mixed Model Comparisons for Errors"),
                    note = c(
                      "AIC = Akaike Information Criterion; BIC = Bayesian Information Criterion; RT = reaction time; CL = cognitive load; SEval = social evaluation."
                    ))

save_as_docx(table, path = "TablesFigures/Table S3 - ADES Model Comparison Errors.docx")

```



Differences between conditions

```{r}
m_eustress1 <- lmer(Eustress ~ CL*Evaluation + (CL + Evaluation|ID),
           data=main_df, REML = T)
m_eustress2 <- lmer(Eustress ~ CL+Evaluation + (CL + Evaluation|ID),
                    data=main_df, REML = T)

AIC(m_eustress1) - AIC(m_eustress2)
summary(m_eustress1)
effectsize(m_eustress1)

estimate_means(m_eustress1, ~CL*Evaluation)


m_distress1 <- lmer(Distress ~ CL*Evaluation + (CL + Evaluation|ID),
                   data=main_df, REML = T)
m_distress2 <- lmer(Distress ~ CL+Evaluation + (CL + Evaluation|ID),
                    data=main_df, REML = T)

AIC(m_distress1) - AIC(m_distress2)
summary(m_distress1)
effectsize(m_distress1)

estimate_means(m_distress1, ~CL*Evaluation)


m_rat1 <- lmer(ratio ~ CL*Evaluation + (CL + Evaluation|ID),
                    data=main_df, REML = T)
m_rat2 <- lmer(ratio ~ CL+Evaluation + (CL + Evaluation|ID),
                    data=main_df, REML = T)

AIC(m_rat1) - AIC(m_rat2)
summary(m_rat1)
effectsize(m_rat1)

estimate_means(m_rat1, ~CL*Evaluation)
```


# Version infomation

```{r}
devtools::session_info()
```
